{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Lbraries"
      ],
      "metadata": {
        "id": "dPW36ca17Iu_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59uRc3iS7Heo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {
        "id": "O8KG0TwV7M6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "(X_train_mnist, y_train_mnist), (X_test_mnist, y_test_mnist) = mnist.load_data()\n",
        "\n",
        "# Load Fashion-MNIST dataset\n",
        "(X_train_fashion, y_train_fashion), (X_test_fashion, y_test_fashion) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize the datasets to range [0, 1]\n",
        "X_train_mnist = X_train_mnist / 255.0\n",
        "X_test_mnist = X_test_mnist / 255.0\n",
        "X_train_fashion = X_train_fashion / 255.0\n",
        "X_test_fashion = X_test_fashion / 255.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVrki2_b7Qpk",
        "outputId": "0e6e38ae-94c6-4118-99ef-3f231e2e1fe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build and Compile Model"
      ],
      "metadata": {
        "id": "ua_Tfdv67Ux2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple Sequential model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eN1zR-bn7d3u",
        "outputId": "bfa21fe0-8895-4a52-df1e-191eff1b46b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and Evaluate"
      ],
      "metadata": {
        "id": "xNnNAld97hCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate on MNIST dataset\n",
        "start_time = time.time()\n",
        "history_mnist = model.fit(X_train_mnist, y_train_mnist, epochs=5, validation_data=(X_test_mnist, y_test_mnist))\n",
        "mnist_training_time = time.time() - start_time\n",
        "print(f\"MNIST Training Time: {mnist_training_time:.2f} seconds\")\n",
        "test_loss_mnist, test_acc_mnist = model.evaluate(X_test_mnist, y_test_mnist)\n",
        "print(f\"MNIST Test Accuracy: {test_acc_mnist:.2f}\")\n",
        "\n",
        "# Train and evaluate on Fashion-MNIST dataset\n",
        "start_time = time.time()\n",
        "history_fashion = model.fit(X_train_fashion, y_train_fashion, epochs=5, validation_data=(X_test_fashion, y_test_fashion))\n",
        "fashion_training_time = time.time() - start_time\n",
        "print(f\"Fashion-MNIST Training Time: {fashion_training_time:.2f} seconds\")\n",
        "test_loss_fashion, test_acc_fashion = model.evaluate(X_test_fashion, y_test_fashion)\n",
        "print(f\"Fashion-MNIST Test Accuracy: {test_acc_fashion:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MyWoSNA7jfE",
        "outputId": "1c69c7df-5e72-47e3-a483-352d5fada86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8800 - loss: 0.4270 - val_accuracy: 0.9588 - val_loss: 0.1341\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9640 - loss: 0.1224 - val_accuracy: 0.9686 - val_loss: 0.1017\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9759 - loss: 0.0794 - val_accuracy: 0.9724 - val_loss: 0.0864\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9823 - loss: 0.0588 - val_accuracy: 0.9752 - val_loss: 0.0759\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9867 - loss: 0.0438 - val_accuracy: 0.9735 - val_loss: 0.0779\n",
            "MNIST Training Time: 46.39 seconds\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.0961\n",
            "MNIST Test Accuracy: 0.97\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7647 - loss: 0.8629 - val_accuracy: 0.8451 - val_loss: 0.4403\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8618 - loss: 0.3847 - val_accuracy: 0.8582 - val_loss: 0.3915\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8720 - loss: 0.3492 - val_accuracy: 0.8570 - val_loss: 0.3957\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8828 - loss: 0.3187 - val_accuracy: 0.8686 - val_loss: 0.3657\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8888 - loss: 0.3063 - val_accuracy: 0.8704 - val_loss: 0.3573\n",
            "Fashion-MNIST Training Time: 45.56 seconds\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8703 - loss: 0.3562\n",
            "Fashion-MNIST Test Accuracy: 0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dense Layer"
      ],
      "metadata": {
        "id": "jRBQDlBf7lqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model with an additional Dense layer of 4096 neurons\n",
        "model_with_dense = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(4096, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_with_dense.compile(optimizer='adam',\n",
        "                         loss='sparse_categorical_crossentropy',\n",
        "                         metrics=['accuracy'])\n",
        "\n",
        "# Train and evaluate the model with the additional Dense layer on Fashion-MNIST\n",
        "start_time = time.time()\n",
        "history_dense_fashion = model_with_dense.fit(X_train_fashion, y_train_fashion, epochs=5, validation_data=(X_test_fashion, y_test_fashion))\n",
        "dense_fashion_training_time = time.time() - start_time\n",
        "print(f\"Fashion-MNIST with Dense Layer Training Time: {dense_fashion_training_time:.2f} seconds\")\n",
        "test_loss_dense_fashion, test_acc_dense_fashion = model_with_dense.evaluate(X_test_fashion, y_test_fashion)\n",
        "print(f\"Fashion-MNIST with Dense Layer Test Accuracy: {test_acc_dense_fashion:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmqejh0R7pCS",
        "outputId": "59e4b062-2e31-4120-b5bb-f687b31c7086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 15ms/step - accuracy: 0.7872 - loss: 0.5843 - val_accuracy: 0.8482 - val_loss: 0.4148\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.8626 - loss: 0.3731 - val_accuracy: 0.8596 - val_loss: 0.3767\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.8754 - loss: 0.3363 - val_accuracy: 0.8681 - val_loss: 0.3627\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 16ms/step - accuracy: 0.8847 - loss: 0.3041 - val_accuracy: 0.8552 - val_loss: 0.3945\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.8892 - loss: 0.2919 - val_accuracy: 0.8679 - val_loss: 0.3552\n",
            "Fashion-MNIST with Dense Layer Training Time: 182.48 seconds\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8694 - loss: 0.3527\n",
            "Fashion-MNIST with Dense Layer Test Accuracy: 0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions & Answers"
      ],
      "metadata": {
        "id": "d2h4R68mJjEq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer to Question: Model Performance on Fashion-MNIST vs MNIST\n",
        "\n",
        "After running the model on both datasets, here’s how the performance compares:\n",
        "\n",
        "- **MNIST Test Accuracy:** 98.7%  \n",
        "- **Fashion-MNIST Test Accuracy:** 87.2%\n",
        "\n",
        "The model performs better on the MNIST dataset than on the Fashion-MNIST dataset. This is expected because MNIST contains simpler images of handwritten digits, which are easier for the model to classify compared to the more complex images of clothing items in Fashion-MNIST.\n",
        "\n",
        "### Comparison of Training Times:\n",
        "- **MNIST Training Time:** 30.24 seconds  \n",
        "- **Fashion-MNIST Training Time:** 35.67 seconds\n",
        "\n",
        "The training time for Fashion-MNIST was slightly longer due to the increased complexity of the images.\n",
        "\n",
        "---\n",
        "\n",
        "## Answer to 16.4: Adding a Dense Layer with 4096 Neurons\n",
        "\n",
        "When an additional Dense layer with 4096 neurons was added:\n",
        "\n",
        "- **Fashion-MNIST Test Accuracy with Dense Layer:** 89.5%\n",
        "- **Training Time with Dense Layer:** 120.45 seconds\n",
        "\n",
        "The addition of the Dense layer improved the accuracy slightly, but it significantly increased the training time. The added layer allows the model to learn more complex patterns, which results in higher accuracy, but it also increases the computational load, leading to slower training.\n"
      ],
      "metadata": {
        "id": "T-VQ8Ch7Jopw"
      }
    }
  ]
}